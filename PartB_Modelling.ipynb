{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab4eb0d",
   "metadata": {},
   "source": [
    "# Part B – Predictive Modelling\n",
    "\n",
    "This notebook focuses on predictive modelling using the restaurant dataset.  \n",
    "We will cover two tasks:  \n",
    "1. **Regression** – predicting the cost of restaurants.  \n",
    "2. **Classification** – predicting rating categories.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0d8d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10500, 17)\n",
      "Missing values:\n",
      " address             0\n",
      "cost              346\n",
      "cuisine             0\n",
      "lat               192\n",
      "link                0\n",
      "lng               192\n",
      "phone               0\n",
      "rating_number    3316\n",
      "rating_text      3316\n",
      "subzone             0\n",
      "title               0\n",
      "type               48\n",
      "votes            3316\n",
      "groupon             0\n",
      "color               0\n",
      "cost_2            346\n",
      "cuisine_color       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>cost</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>lat</th>\n",
       "      <th>link</th>\n",
       "      <th>lng</th>\n",
       "      <th>phone</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>rating_text</th>\n",
       "      <th>subzone</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>votes</th>\n",
       "      <th>groupon</th>\n",
       "      <th>color</th>\n",
       "      <th>cost_2</th>\n",
       "      <th>cuisine_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>371A Pitt Street, CBD, Sydney</td>\n",
       "      <td>50.0</td>\n",
       "      <td>['Hot Pot', 'Korean BBQ', 'BBQ', 'Korean']</td>\n",
       "      <td>-33.876059</td>\n",
       "      <td>https://www.zomato.com/sydney/sydney-madang-cbd</td>\n",
       "      <td>151.207605</td>\n",
       "      <td>02 8318 0406</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>CBD</td>\n",
       "      <td>Sydney Madang</td>\n",
       "      <td>['Casual Dining']</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>False</td>\n",
       "      <td>#e15307</td>\n",
       "      <td>5.243902</td>\n",
       "      <td>#6f706b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shop 7A, 2 Huntley Street, Alexandria, Sydney</td>\n",
       "      <td>80.0</td>\n",
       "      <td>['Cafe', 'Coffee and Tea', 'Salad', 'Poké']</td>\n",
       "      <td>-33.910999</td>\n",
       "      <td>https://www.zomato.com/sydney/the-grounds-of-a...</td>\n",
       "      <td>151.193793</td>\n",
       "      <td>02 9699 2225</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>The Grounds of Alexandria, Alexandria</td>\n",
       "      <td>The Grounds of Alexandria Cafe</td>\n",
       "      <td>['Café']</td>\n",
       "      <td>3236.0</td>\n",
       "      <td>False</td>\n",
       "      <td>#9c3203</td>\n",
       "      <td>7.560976</td>\n",
       "      <td>#6f706b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Level G, The Darling at the Star, 80 Pyrmont ...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>['Japanese']</td>\n",
       "      <td>-33.867971</td>\n",
       "      <td>https://www.zomato.com/sydney/sokyo-pyrmont</td>\n",
       "      <td>151.195210</td>\n",
       "      <td>1800 700 700</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>The Star, Pyrmont</td>\n",
       "      <td>Sokyo</td>\n",
       "      <td>['Fine Dining']</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>False</td>\n",
       "      <td>#7f2704</td>\n",
       "      <td>10.650407</td>\n",
       "      <td>#6f706b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sydney Opera House, Bennelong Point, Circular...</td>\n",
       "      <td>270.0</td>\n",
       "      <td>['Modern Australian']</td>\n",
       "      <td>-33.856784</td>\n",
       "      <td>https://www.zomato.com/sydney/bennelong-restau...</td>\n",
       "      <td>151.215297</td>\n",
       "      <td>02 9240 8000</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Circular Quay</td>\n",
       "      <td>Bennelong Restaurant</td>\n",
       "      <td>['Fine Dining', 'Bar']</td>\n",
       "      <td>278.0</td>\n",
       "      <td>False</td>\n",
       "      <td>#7f2704</td>\n",
       "      <td>22.235772</td>\n",
       "      <td>#4186f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 Campbell Street, Chinatown, Sydney</td>\n",
       "      <td>55.0</td>\n",
       "      <td>['Thai', 'Salad']</td>\n",
       "      <td>-33.879035</td>\n",
       "      <td>https://www.zomato.com/sydney/chat-thai-chinatown</td>\n",
       "      <td>151.206409</td>\n",
       "      <td>02 8317 4811</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Chinatown</td>\n",
       "      <td>Chat Thai</td>\n",
       "      <td>['Casual Dining']</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>#a83703</td>\n",
       "      <td>5.630081</td>\n",
       "      <td>#6f706b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address   cost  \\\n",
       "0                      371A Pitt Street, CBD, Sydney   50.0   \n",
       "1      Shop 7A, 2 Huntley Street, Alexandria, Sydney   80.0   \n",
       "2   Level G, The Darling at the Star, 80 Pyrmont ...  120.0   \n",
       "3   Sydney Opera House, Bennelong Point, Circular...  270.0   \n",
       "4              20 Campbell Street, Chinatown, Sydney   55.0   \n",
       "\n",
       "                                       cuisine        lat  \\\n",
       "0   ['Hot Pot', 'Korean BBQ', 'BBQ', 'Korean'] -33.876059   \n",
       "1  ['Cafe', 'Coffee and Tea', 'Salad', 'Poké'] -33.910999   \n",
       "2                                 ['Japanese'] -33.867971   \n",
       "3                        ['Modern Australian'] -33.856784   \n",
       "4                            ['Thai', 'Salad'] -33.879035   \n",
       "\n",
       "                                                link         lng  \\\n",
       "0    https://www.zomato.com/sydney/sydney-madang-cbd  151.207605   \n",
       "1  https://www.zomato.com/sydney/the-grounds-of-a...  151.193793   \n",
       "2        https://www.zomato.com/sydney/sokyo-pyrmont  151.195210   \n",
       "3  https://www.zomato.com/sydney/bennelong-restau...  151.215297   \n",
       "4  https://www.zomato.com/sydney/chat-thai-chinatown  151.206409   \n",
       "\n",
       "          phone  rating_number rating_text  \\\n",
       "0  02 8318 0406            4.0   Very Good   \n",
       "1  02 9699 2225            4.6   Excellent   \n",
       "2  1800 700 700            4.9   Excellent   \n",
       "3  02 9240 8000            4.9   Excellent   \n",
       "4  02 8317 4811            4.5   Excellent   \n",
       "\n",
       "                                 subzone                           title  \\\n",
       "0                                    CBD                   Sydney Madang   \n",
       "1  The Grounds of Alexandria, Alexandria  The Grounds of Alexandria Cafe   \n",
       "2                      The Star, Pyrmont                           Sokyo   \n",
       "3                          Circular Quay            Bennelong Restaurant   \n",
       "4                              Chinatown                       Chat Thai   \n",
       "\n",
       "                     type   votes  groupon    color     cost_2 cuisine_color  \n",
       "0       ['Casual Dining']  1311.0    False  #e15307   5.243902       #6f706b  \n",
       "1                ['Café']  3236.0    False  #9c3203   7.560976       #6f706b  \n",
       "2         ['Fine Dining']  1227.0    False  #7f2704  10.650407       #6f706b  \n",
       "3  ['Fine Dining', 'Bar']   278.0    False  #7f2704  22.235772       #4186f4  \n",
       "4       ['Casual Dining']  2150.0    False  #a83703   5.630081       #6f706b  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv(\"data/zomato_df_final_data.csv\")\n",
    "\n",
    "# Basic check\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54d871a",
   "metadata": {},
   "source": [
    "### 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9a7cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning:\n",
      " address          0\n",
      "cost             0\n",
      "cuisine          0\n",
      "lat              0\n",
      "link             0\n",
      "lng              0\n",
      "phone            0\n",
      "rating_number    0\n",
      "rating_text      0\n",
      "subzone          0\n",
      "title            0\n",
      "type             0\n",
      "votes            0\n",
      "groupon          0\n",
      "color            0\n",
      "cost_2           0\n",
      "cuisine_color    0\n",
      "dtype: int64\n",
      "Shape: (6969, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AkeyT\\AppData\\Local\\Temp\\ipykernel_22204\\4005009771.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[\"cost\"] = df_cleaned[\"cost\"].fillna(df_cleaned[\"cost\"].median())\n",
      "C:\\Users\\AkeyT\\AppData\\Local\\Temp\\ipykernel_22204\\4005009771.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[\"type\"] = df_cleaned[\"type\"].fillna(df_cleaned[\"type\"].mode()[0])\n"
     ]
    }
   ],
   "source": [
    "# Drop rows missing target values\n",
    "df_cleaned = df.dropna(subset=[\"rating_number\", \"votes\"])\n",
    "\n",
    "# Fill missing cost with median\n",
    "df_cleaned[\"cost\"] = df_cleaned[\"cost\"].fillna(df_cleaned[\"cost\"].median())\n",
    "\n",
    "# Fill missing type with mode\n",
    "df_cleaned[\"type\"] = df_cleaned[\"type\"].fillna(df_cleaned[\"type\"].mode()[0])\n",
    "\n",
    "# Drop any remaining missing rows\n",
    "df_cleaned = df_cleaned.dropna()\n",
    "\n",
    "# Check result\n",
    "print(\"After cleaning:\\n\", df_cleaned.isnull().sum())\n",
    "print(\"Shape:\", df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31796a",
   "metadata": {},
   "source": [
    "**Handle Missing Data**\n",
    "\n",
    "Dropped rows with missing `rating_number` or `votes`. \n",
    "Filled missing `cost` with median and `type` with mode. \n",
    "Dropped remaining NAs. Final shape: ~8,400 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d59816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features/target\n",
    "X = df_cleaned.drop(columns=[\"rating_number\", \"rating_text\"])\n",
    "y = df_cleaned[\"rating_number\"]\n",
    "\n",
    "# Identify columns\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Define pipelines\n",
    "num_tf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "cat_tf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_tf, num_cols),\n",
    "    (\"cat\", cat_tf, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f834780",
   "metadata": {},
   "source": [
    "**Categorical Encoding**\n",
    "\n",
    "We applied One-Hot Encoding to all categorical features, with missing values imputed using the most frequent category. Numerical columns were scaled after imputing median values. This step prepares the data for regression/classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e546d",
   "metadata": {},
   "source": [
    "### 2. Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4bdb63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A (LinearRegression/sklearn) MSE: 0.0071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Combine preprocessor + model\n",
    "model_a = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Train\n",
    "model_a.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model_a.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse_a = mean_squared_error(y_test, y_pred)\n",
    "print(\"Model A (LinearRegression/sklearn) MSE:\", round(mse_a, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac967504",
   "metadata": {},
   "source": [
    "**About moudle A**\n",
    "We trained a linear regression model to predict `rating_number` using Scikit-Learn. The pipeline included preprocessing (imputation, scaling, encoding) and a linear regression model. The dataset was split into 80% training and 20% testing.\n",
    "\n",
    "**Performance:**\n",
    "- **Mean Squared Error (MSE)**: 0.0071\n",
    "\n",
    "This low MSE indicates that the model performs reasonably well in predicting average ratings, though further validation is needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a6d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model B (Gradient Descent) MSE: 0.161\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select features (exclude target)\n",
    "X = df_cleaned[[\"votes\", \"cost\"]]\n",
    "y = df_cleaned[\"rating_number\"]\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features for stability\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Add bias term\n",
    "X_train_b = np.c_[np.ones((X_train_scaled.shape[0], 1)), X_train_scaled]\n",
    "X_test_b = np.c_[np.ones((X_test_scaled.shape[0], 1)), X_test_scaled]\n",
    "\n",
    "# Initialize parameters\n",
    "theta = np.random.randn(X_train_b.shape[1], 1)\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 0.01      # smaller learning rate\n",
    "n_iter = 5000  # more iterations\n",
    "m = len(X_train_b)\n",
    "\n",
    "# Gradient descent loop\n",
    "y_train_np = y_train.values.reshape(-1, 1)\n",
    "for i in range(n_iter):\n",
    "    gradients = 2/m * X_train_b.T @ (X_train_b @ theta - y_train_np)\n",
    "    theta -= lr * gradients\n",
    "\n",
    "# Predictions and MSE\n",
    "y_pred = X_test_b @ theta\n",
    "mse_gd = np.mean((y_pred.flatten() - y_test.values)**2)\n",
    "\n",
    "print(\"Model B (Gradient Descent) MSE:\", round(mse_gd, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d684d",
   "metadata": {},
   "source": [
    "**3. Classification Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b766887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Copy data\n",
    "df_cls = df_cleaned.copy()\n",
    "\n",
    "# Map rating_text to binary class\n",
    "class_map = {\n",
    "    'Poor': 0,\n",
    "    'Average': 0,\n",
    "    'Good': 1,\n",
    "    'Very Good': 1,\n",
    "    'Excellent': 1\n",
    "}\n",
    "df_cls[\"rating_binary\"] = df_cls[\"rating_text\"].map(class_map)\n",
    "\n",
    "# Drop rows with unmapped values (if any)\n",
    "df_cls = df_cls.dropna(subset=[\"rating_binary\"])\n",
    "\n",
    "# Select features and target\n",
    "X = df_cls[[\"votes\", \"cost\"]]  # You can add more features later\n",
    "y = df_cls[\"rating_binary\"].astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad9090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[860  47]\n",
      " [180 307]]\n",
      "Precision: 0.867\n",
      "Recall:    0.630\n",
      "F1 Score:  0.730\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       907\n",
      "           1       0.87      0.63      0.73       487\n",
      "\n",
      "    accuracy                           0.84      1394\n",
      "   macro avg       0.85      0.79      0.81      1394\n",
      "weighted avg       0.84      0.84      0.83      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Train logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall:    {recall:.3f}\")\n",
    "print(f\"F1 Score:  {f1:.3f}\")\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ad181",
   "metadata": {},
   "source": [
    " **Logistic Regression Results Analysis**\n",
    "\n",
    "The logistic regression model achieved an overall accuracy of **84%**, with a precision of **0.867**, recall of **0.630**, and F1 score of **0.730** for the positive class (\"Good\", \"Very Good\", \"Excellent\"). The confusion matrix shows the model performs well in identifying low-rated restaurants (Class 0) with high recall (0.95), but is less effective at detecting high-rated ones, with more false negatives and a lower recall (0.63). This indicates the model is more conservative in assigning the positive class and may underpredict high-quality restaurants. Overall, the model demonstrates reasonable performance and serves as a solid baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'cuisine_diversity' = count of distinct cuisines\n",
    "df_binary[\"cuisine_diversity\"] = df_binary[\"cuisine\"].apply(lambda x: len(str(x).split(',')))\n",
    "\n",
    "# Create 'num_cuisines' = same as cuisine_diversity\n",
    "df_binary[\"num_cuisines\"] = df_binary[\"cuisine_diversity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"cost\", \"votes\", \"cuisine_diversity\", \"num_cuisines\"]\n",
    "X = df_binary[features]\n",
    "y = df_binary[\"rating_class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model  Accuracy  Precision  Recall  F1 Score\n",
      "0  Gradient Boosted Trees     0.870      0.809   0.814     0.812\n",
      "1                     SVM     0.858      0.834   0.733     0.781\n",
      "2           Random Forest     0.839      0.786   0.729     0.757\n"
     ]
    }
   ],
   "source": [
    "# Train and compare three classifiers (handles missing values and scales features)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Prepare data\n",
    "features = [\"cost\", \"votes\", \"cuisine_diversity\", \"num_cuisines\"]\n",
    "X = df_binary[features].copy()\n",
    "y = df_binary[\"rating_class\"].copy()\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Impute missing values (fit on train only)\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_train_imp = pd.DataFrame(imp.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_imp  = pd.DataFrame(imp.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Scale features (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_imp), columns=X_train_imp.columns, index=X_train_imp.index)\n",
    "X_test_scaled  = pd.DataFrame(scaler.transform(X_test_imp), columns=X_test_imp.columns, index=X_test_imp.index)\n",
    "\n",
    "# Models to train\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    \"Gradient Boosted Trees\": GradientBoostingClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Train, predict and collect metrics\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    # Use scaled data for all models (scaling is benign for tree models)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": round(accuracy_score(y_test, y_pred), 3),\n",
    "        \"Precision\": round(precision_score(y_test, y_pred), 3),\n",
    "        \"Recall\": round(recall_score(y_test, y_pred), 3),\n",
    "        \"F1 Score\": round(f1_score(y_test, y_pred), 3)\n",
    "    })\n",
    "\n",
    "# Show comparison\n",
    "comparison_df = pd.DataFrame(results).sort_values(\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b927a9a8",
   "metadata": {},
   "source": [
    "**Classification Model Comparison and Analysis**\n",
    "\n",
    "Three classification models were trained to predict simplified restaurant rating classes using selected features (`cost`, `votes`, `cuisine_diversity`, `num_cuisines`). Based on the evaluation metrics, **Gradient Boosted Trees** outperformed the other two models in terms of overall performance, achieving the highest accuracy (0.870) and F1 score (0.812). It effectively balanced precision and recall, making it a strong candidate for deployment.\n",
    "\n",
    "The **SVM model** also performed well, particularly in precision (0.834), but had slightly lower recall, which affected its F1 score. **Random Forest** showed the lowest performance among the three, although still acceptable, with a relatively lower recall (0.729), indicating it missed more positive samples.\n",
    "\n",
    "Overall, Gradient Boosted Trees provided the most balanced and reliable classification performance on this dataset. However, its training speed and scalability may be a concern for larger datasets, which will be further evaluated in the PySpark comparison."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
